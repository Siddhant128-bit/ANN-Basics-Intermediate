{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>  Classification of Multiple Classes. </h1>\n",
    "\n",
    "<p> &nbsp;&nbsp; Sometimes Neural Networks have to predict multiple classes, More then one class solution. There are 2 ways to solve this problem \n",
    "<ol>\n",
    "    <li> Multi Label Classification </li>\n",
    "    <li> Multi Class Classification </li>\n",
    "</ol>\n",
    "\n",
    "<p>&nbsp; 1. Multi Label Classification </br>\n",
    "&nbsp;&nbsp;&nbsp; In this approach we basically have multiple outputs for multiple classes and get output as 1 or 0 for each neurons output. It invovles one hot encoding process of the dataset </p>\n",
    "\n",
    "<p>&nbsp; 2. Multi Class Classification </br>\n",
    "&nbsp;&nbsp;&nbsp; In this approach we use just the single output neuron to predict different classess itself. This involves label encoding process of dataset </p>\n",
    "\n",
    "<img width=\"1200\" height=\"800\" src='https://www.section.io/engineering-education/multi-label-classification-with-scikit-multilearn/label-powerset.png'>\n",
    "\n",
    "<p> Let's Work on Multi Class Classification first after which we can move to multi label classification </br>\n",
    "We Can work with the <b><i> IRIS FLOWER DATASET </i></b>\n",
    "\n",
    "<h5 align='center'> Dataset: </h5>\n",
    "<img src='https://miro.medium.com/max/638/0*2c7voFri9cIXGrc4'>\n",
    "\n",
    "<h3 align='center'> 0. Installing Dependencies </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy \n",
    "!pip install pandas \n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'> 1. Importing Dependenceis </h3>\n",
    "\n",
    "<p> We are going to import all the dependencies for this project. The Dependencies are: </p>\n",
    "<ul>\n",
    "    <li> Pandas </li>\n",
    "    <li> Numpy </li>\n",
    "    <li>tensorflow </li>\n",
    "    <li> sklearn </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'> 2. Handling Dataset </h3>\n",
    "<p> &nbsp;&nbsp;&nbsp; We are going to handle the dataset in following ways: </p>\n",
    "<ul>\n",
    "    <li> Importing Dataset </li>\n",
    "    <li> Label encoding </li>\n",
    "    <li> One hot encoding </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    data=pd.read_csv(path)\n",
    "    return data \n",
    "\n",
    "def get_class_dict(dataset):\n",
    "    class_list=list(set(dataset['species'].to_list()))\n",
    "    class_dct={}\n",
    "    for i in range(len(class_list)):\n",
    "        class_dct[class_list[i]]=i\n",
    "    print(class_dct)\n",
    "\n",
    "dataset=read_dataset('IRIS.csv')\n",
    "classes_list=get_class_dict(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3d2f78e555183a881cae8393ce673a4ac506717ad392b2f660077200b1aa750"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>  Classification of Multiple Classes. </h1>\n",
    "\n",
    "<p> &nbsp;&nbsp; Sometimes Neural Networks have to predict multiple classes, More then one class solution. There are 2 ways to solve this problem \n",
    "<ol>\n",
    "    <li> Multi Label Classification </li>\n",
    "    <li> Multi Class Classification </li>\n",
    "</ol>\n",
    "\n",
    "<p>&nbsp; 1. Multi Label Classification </br>\n",
    "&nbsp;&nbsp;&nbsp; In this approach we basically have multiple outputs for multiple classes and get output as 1 or 0 for each neurons output. It invovles one hot encoding process of the dataset </p>\n",
    "\n",
    "<p>&nbsp; 2. Multi Class Classification </br>\n",
    "&nbsp;&nbsp;&nbsp; In this approach we use just the single output neuron to predict different classess itself. This involves label encoding process of dataset </p>\n",
    "\n",
    "<img width=\"1200\" height=\"800\" src='https://www.section.io/engineering-education/multi-label-classification-with-scikit-multilearn/label-powerset.png'>\n",
    "\n",
    "<p> Let's Work on Multi Class Classification first after which we can move to multi label classification </br>\n",
    "We Can work with the <b><i> IRIS FLOWER DATASET </i></b>\n",
    "\n",
    "<h5 align='center'> Dataset: </h5>\n",
    "<img src='https://miro.medium.com/max/638/0*2c7voFri9cIXGrc4'>\n",
    "\n",
    "<h3 align='center'> 0. Installing Dependencies </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy \n",
    "!pip install pandas \n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'> 1. Importing Dependenceis </h3>\n",
    "\n",
    "<p> We are going to import all the dependencies for this project. The Dependencies are: </p>\n",
    "<ul>\n",
    "    <li> Pandas </li>\n",
    "    <li> Numpy </li>\n",
    "    <li>tensorflow </li>\n",
    "    <li> sklearn </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'> 2. Handling Dataset </h3>\n",
    "<p> &nbsp;&nbsp;&nbsp; We are going to handle the dataset in following ways: </p>\n",
    "<ul>\n",
    "    <li> Importing Dataset </li>\n",
    "    <li> Label encoding </li>\n",
    "    <li> One hot encoding </li>\n",
    "</ul>\n",
    "\n",
    "<h4> Importing Dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    data=pd.read_csv(path)\n",
    "    return data \n",
    "\n",
    "def get_class_dict(dataset):\n",
    "    class_list=list(set(dataset['species'].to_list()))\n",
    "    class_dct={}\n",
    "    for i in range(len(class_list)):\n",
    "        class_dct[class_list[i]]=i\n",
    "    return class_dct\n",
    "\n",
    "dataset=read_dataset('IRIS.csv')\n",
    "classes_dict=get_class_dict(dataset)\n",
    "#Creating copies of dataset so it can be used to obtain 2 values.\n",
    "d_temp1=dataset.copy()\n",
    "d_temp2=dataset.copy()\n",
    "del dataset #Deleting Dataset freeing some space\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Label Encodng </h4>\n",
    "<p>&nbsp; &nbsp; &nbsp; We will have each class value in dictionary as label for the class this method of getting out is called label encoding we will use it for multi class classification </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding_dataset(d_temp1,class_dict):\n",
    "    for i in class_dict.keys():\n",
    "        d_temp1.loc[d_temp1['species']==i,'species']=class_dict[i]\n",
    "    \n",
    "    return d_temp1        \n",
    "\n",
    "dataset_label_encoded=label_encoding_dataset(d_temp1,classes_dict)\n",
    "dataset_label_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> One Hot Encoding <h4>\n",
    "<p>&nbsp; &nbsp; &nbsp; Now we are going to have 3 labels each will have 1 or 0 present on it This approach will give us 3 outputs and each output will have 0 or 1 present on it demonstrating yes or no of the output this technique is called one hot encoding and this classification is called Multi Label classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_dataset(dataset,classes_dict):\n",
    "    def encode(x,i):\n",
    "        if x==i:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "\n",
    "    def add_columns(dataset,classes_dict):\n",
    "        dataset_final=dataset.drop(columns=['species'])\n",
    "        for i in classes_dict.keys():\n",
    "            dataset_final[i]=dataset['species'].apply(encode,args =(i,))\n",
    "        return dataset_final\n",
    "\n",
    "\n",
    "    dataset_final=add_columns(dataset,classes_dict)\n",
    "    return dataset_final\n",
    "\n",
    "dataset_one_hot_encoded=one_hot_encoding_dataset(d_temp2,classes_dict)\n",
    "dataset_one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'>3. Multi Class Classification </h3>\n",
    "<p> &nbsp; &nbsp; &nbsp; Multi Class classification will have single output in the neural network that will work out different output values for output neurons.We are going to use softmax for activation function to get the required output.We can see the following image to learn more </p>\n",
    "<img src='https://miro.medium.com/max/1400/1*ReYpdIZ3ZSAPb2W8cJpkBg.jpeg'>\n",
    "\n",
    "</br> Our final output neuron of the neural network will be just one consisting of 3 possible values Making our entire architecture of Neural Network as:\n",
    "</br></br>\n",
    "<img src='./Diagrams/Multi Class Classification Architecture.jpg'>\n",
    "\n",
    "<p> The number of neuron assigned to each layer is arbitary at this point but the final layer should have as many neurons as classes to predict because of how softmax activation function works </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model=tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=9,activation='sigmoid',input_dim=4))\n",
    "    model.add(tf.keras.layers.Dense(units=18,activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(units=9,activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(units=3,activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(units=3,activation='softmax'))\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model\n",
    "\n",
    "def get_X_Y_label_encoded(dataset):\n",
    "    X=np.array(dataset.drop(columns=['species'])).astype(np.float32)\n",
    "    Y=(np.array(dataset['species']).astype(np.float32)).reshape(-1,1)\n",
    "    return X,Y\n",
    "\n",
    "multi_class_model=create_model()\n",
    "X,Y=get_X_Y_label_encoded(dataset_label_encoded)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.33, random_state=42)\n",
    "history=multi_class_model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5000,batch_size=64)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align='center'> 3.1 Testing </h3>\n",
    "\n",
    "We are going to input new custom dataset to see how well it predicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(model,input_user):\n",
    "    output=model.predict([input_user])\n",
    "    output=np.argmax(output[0])\n",
    "    output=list({i for i in classes_dict.keys() if classes_dict[i]==output})\n",
    "    return output[0]\n",
    "\n",
    "def get_input_from_users(length):\n",
    "    input_user=[]\n",
    "    for i in range(1,length+1):\n",
    "        input_user.append(float(input(f'Enter {i} ipnut ')))\n",
    "    return input_user\n",
    "    \n",
    "input_1=[5.1,3.5,1.4,0.2]\n",
    "print(predict_output(multi_class_model,input_1))\n",
    "\n",
    "input_2=get_input_from_users(dataset_label_encoded.shape[1]-1)\n",
    "print(predict_output(multi_class_model,input_2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3d2f78e555183a881cae8393ce673a4ac506717ad392b2f660077200b1aa750"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
